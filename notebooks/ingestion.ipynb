{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from unstructured.partition.pdf import partition_pdf\n",
    "from langchain_core.documents import Document\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "file_path = \"C:/Users/User/Downloads/tmj_rag_app/data/pdfs\"\n",
    "base_file_name = \"tmjDoc1\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import env variables\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: No languages specified, defaulting to English.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `max_size` parameter is deprecated and will be removed in v4.26. Please specify in `size['longest_edge'] instead`.\n"
     ]
    }
   ],
   "source": [
    "# Partition the PDF file\n",
    "elements = partition_pdf(\n",
    "    filename=f\"{file_path}/{base_file_name}.pdf\",\n",
    "    strategy=\"hi_res\",\n",
    "    infer_table_structure=True\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the elements partitioned from the PDF file\n",
    "for i, element in enumerate(elements):\n",
    "    print(f\"\\n--- Element {i} ---\")\n",
    "    print(f\"Type: {element.category}\")\n",
    "    print(f\"Text preview: {element.text[:100]}...\")\n",
    "    print(f\"Metadata: {element.metadata}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to LangChain Documents\n",
    "docs = []\n",
    "for el in elements:\n",
    "    text = getattr(el, \"text\", None)\n",
    "    if not text:\n",
    "        continue\n",
    "    meta = el.to_dict().get(\"metadata\", {}) or {}\n",
    "    docs.append(\n",
    "        Document(\n",
    "            page_content=text,\n",
    "            metadata={\n",
    "                \"source\": base_file_name,\n",
    "                \"page_number\": meta.get(\"page_number\"),\n",
    "                \"type\": el.category if hasattr(el, \"category\") else meta.get(\"type\"),\n",
    "            },\n",
    "        )\n",
    "    )\n",
    "\n",
    "splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "chunked_docs = splitter.split_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Print the chunked documents\n",
    "for i, doc in enumerate(chunked_docs, 1):\n",
    "    meta = doc.metadata\n",
    "    print(f\"--- Chunk {i} ---\")\n",
    "    print(f\"source={meta.get('source')} page={meta.get('page_number')} type={meta.get('type')} section={meta.get('section')}\")\n",
    "    print(doc.page_content)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OpenAIEmbeddings(client=<openai.resources.embeddings.Embeddings object at 0x000001A189CB3C80>, async_client=<openai.resources.embeddings.AsyncEmbeddings object at 0x000001A18B106120>, model='text-embedding-3-small', dimensions=None, deployment='text-embedding-ada-002', openai_api_version=None, openai_api_base=None, openai_api_type=None, openai_proxy=None, embedding_ctx_length=8191, openai_api_key=SecretStr('**********'), openai_organization=None, allowed_special=None, disallowed_special=None, chunk_size=1000, max_retries=2, request_timeout=None, headers=None, tiktoken_enabled=True, tiktoken_model_name=None, show_progress_bar=False, model_kwargs={}, skip_empty=False, default_headers=None, default_query=None, retry_min_seconds=4, retry_max_seconds=20, http_client=None, http_async_client=None, check_embedding_ctx_length=True)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create embeddings\n",
    "embeddings = OpenAIEmbeddings(\n",
    "    model=\"text-embedding-3-small\",\n",
    ")\n",
    "\n",
    "vector = embeddings.embed_query(\"Hello world\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
